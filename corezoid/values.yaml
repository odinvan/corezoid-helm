# Global values for subcharts | production
global:
  # second level domain only! / core domain (example: corezoid.com)
  domain: "corezoid.comfy.ua"
  # subdomain / sitename - dev.mpo.corezoid.com (example: dev.mpo)
  subdomain: "main"

  # docker image registry
  imageRegistry: "hub-registry.svc.aku.com"
  #IfNotPresent | Always | Never
  imagePullPolicy: "IfNotPresent"
  repotype: "public"
  product: "corezoid"
  # Ingress annotations
  ingress_tls: true
  ingress:
    deploy_nginx: true
    annotations:
      kubernetes.io/ingress.class: nginx
      cert-manager.io/cluster-issuer: letsencrypt
      # kubernetes.io/ingress.class: alb
      # alb.ingress.kubernetes.io/scheme: internet-facing
      # alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:eu-west-1:305168114386:certificate/5fad3576-220b-4c69-ac85-e56b3fe684bd
      # alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-2-Ext-2018-06
      # alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
      # alb.ingress.kubernetes.io/load-balancer-attributes: "routing.http2.enabled=false"

      # access restriction
      # alb.ingress.kubernetes.io/inbound-cidrs: 8.8.8.8/32, 1.1.1.1/32, 0.0.0.0/0
      # for creating route53 record-set
      # external-dns.alpha.kubernetes.io/hostname: {{ .Values.global.subdomain}}.{{ .Values.global.domain }}

  ################################
  ######## Proxy settings ########
  http_proxy: http://proxy-lt.svc.aku.com:3128

  ###########################################
  ######## Settings for filesystems #########
  # Define global storage class: efs / nfs / manual
  storage: nfs-client
  # Define global storageClass name
  storageClassName: "nfs-client"
  ######## Settings AWS EFS filesystem   ########
  efs:
    awsRegion: "eu-west-1"
    efsFileSystemId: "fs-5b5cee6f"
    ## set true if you choose storage: efs
    enabled: false
  ######## Settings NFS filesystem   ########
  nfs:
    ## set true if you choose storage: nfs
    enabled: false

  nfs-client:
    ## set true if you choose storage: nfs-client
    enabled: true
    server: 172.16.0.11
    path: /opt/nfs/k8s/corezoid

  ########  Settings for stateful services  ########

  #######  PostgreSQL  ########
  ## Supported version  from 9.6.* <
  ## for RDS minimum instance - db.t2.medium / master user set "postgres"
  db:
    # if internal true - create and use internal postgres container
    # if internal false - enable external db, like aws rds
    internal: false
    ## secret configuration for postgresql

    ## pvc name
    persistantVolumeClaimName: "postgresql-pvc"
    secret:
      ## true - secret will be created automaticaly with provided values
      ## false - secret should be created manualy
      create: true
      ## secret name
      name: "postgresql-secret"
      ## for init db and roles dbsuperuser and dbuser cannot be changed (because used as plain text in sql)
      dbsuperuser: "postgres"
      ## password - for dbsuperuser
      dbsuperuserpwd: "ygyegyg8"
      data:
        dbhost: "172.16.7.39"
        dbport: "5000"
        dbuser: "internal_user"
        dbpwd: "8hhgasdgiuf"

    ###### ATENTION! shards_count and shards cant be changed after first init!!!! ####
    # be careful in defining this variable
    # count of shards created in psql, if unset, default - 10
    shards_count: 10
    # count of shards created in psql, if unset, default - 10 - in array format
    shards: ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]

    # set false to disable if you don't want to use PGBouncer recommended - true
    bouncer: true
    bouncer_minReplicas: "2"
    bouncer_maxReplicas: "4"
    bouncer_resources:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "500m"
        memory: "512Mi"
    # Maximum number of client connections allowed.
    maxclientconn: "100000"
    # How many server connections to allow per user/database pair. Can be overridden in the per-database configuration.
    default_pool_size: "5000"
    # Server is released back to pool after transaction finishes. default: session, see man https://wiki.postgresql.org/wiki/PgBouncer
    # transaction | session
    default_pool_mode: transaction

    # Postgres corezoid schema version
    postgres_schema:
      version: "5.7.0"

    rotation:
      ## enabled: true or false
      enabled: true
      # tasks_archive table cleanup period in crontab format
      # minute hour day month dayofweek
      schedule: "0 0 1 * *"

  #######  Redis  ########
  ## Supported version  from > 3.2.4 - 3.2.12

  ## NO CLUSTER Mode!
  redis:
    # if internal true - create and use internal k8s redis container
    # if internal false - enable external redis, like aws elasticache (Engine Version Compatibility: 3.2.10)
    internal: false
    ## pvc name if it already exist or was created manualy
    persistantVolumeClaimName: "redis-pvc"
    ## secret configuration for redis
    secret:
      ## true - secret will be created automatically with provided values
      ## false - secret should be created manually
      create: true
      name: "redis-secret"
      # you can specify different servers for redis for counters, cache and timers  - or specify the same server in variables
      data:
        host: "172.16.6.70"
        port: "6379"
        password: "Acoofelahph4da8Z"
        # default redis for cache
        host_cache: "172.16.6.70"
        port_cache: "6379"
        password_cache: "Acoofelahph4da8Z"
        # default redis for timers
        host_timers: "172.16.6.70"
        port_timers: "6379"
        password_timers: "Acoofelahph4da8Z"



  #######  Elasticsearch  ########
  ## Supported version 6.7.*
  elasticsearch:
    tag: "6.7.1"
    # if internal true - create and use internal elasticsearch container
    # if internal false - enable external elasticsearch, like aws elasticsearch service
    internal: true
    ## secret configuration for elasticsearch
    secret:
      ## true - secret will be created automaticaly with provided values
      ## false - secret should be created manualy
      create: true
      name: "elasticsearch-secret"
      data:
        host: "elasticsearch-elasticsearch-master"
        ## be careful with port - in internal install used 9200, in aws uses 443
        port: "9200"

  #######  RabbitMQ  ########
  ## Supported version  3.8.*
  mq:
    # if internal true - create and use internal rmq container
    # if internal false - enable external rmq (on aws ec2 instances as example)
    internal: false
    ## secret configuration for rabbitmq
    secret:
      ## true - secret will be created automatically with provided values
      ## false - secret should be created manually
      create: true
      name: "rabbitmq-secret"
      data:
        host: "172.16.6.77"
        port: "5672"
        vhost: "/conveyor"
        username: "app-user"
        password: "passwertws"
        rabbitmqErlangCookie: ""
    # vm_memory_high_watermark.relative
    memoryHighWatermark: 0.3

  ########  Settings for Corezoid services  ########
  ## Settings for API Corezoid
  capi:
    tag: "7.7.0.1"
    minReplicas: 2
    maxReplicas: 4
    resources:
      limits:
        cpu: 2
        memory: 2048Mi
      requests:
        cpu: 2
        memory: 2048Mi
    ## restricting user registration only within the domains specified below if enabled
    registration_restriction:
      enable: false
      allowed_domains:
        - "gmail.com"
        - "yahoo.com"
      # Ð¡aptcha when login in UI enable/disable
    capi_front_captcha_disabled: true
    secret:
      ## true - secret will be created automatically with provided values
      ## false - secret should be created manually
      create: true
      name: "capi-secret"
      data:
        # Key for captcha when login in UI
        capi_front_captcha_key: ""
        # Secret for captcha
        capi_backend_captcha_key: ""
    # max req/sec of create|modify|delete for conv|folder|dashboard in 1 sec
    max_reqs_limit: 50000
    # merchant_api settings
    merchant_api:
      skip_otp: true
    # cookie expire time in sec (default 900)
    cookie_expr_time: 7200
    ## Setting for configure frontend
    front_setting:
      # documentation (navigate by clicking on DOCS link)
      doc_host: "doc.corezoid.com"
      doc_index: "/"
      ui:
        # enabled Market button
        market: false
        # button Create -> Bot platform
        bot_platform: true
        # billing button display
        billing: false
        # display of the git_call button
        git_call: false
        # set default company name
        default_company: "Comfy"
        # Tab name
        tab_name: "Corezoid"
        # disable or enable logo on main page
        disabled_auth_logo: false
        # colors
        color_main: "#0791e5"
        color_logo: "#0791e5"
        color_logo_hover: "#056cab"
    ldap_server: "lt-dc2.aku.com"
    ldap_port: "389"
    ldap_base: "dc=aku,dc=com"
    ldap_filter: "sAMAccountName"
    # then this param is true, bind_user_name, bind_user_pass should be filled. if it's false it is not necessary
    ldap_first_bind_user: true
    ldap_bind_user_name: "CN=ldap_aku,OU=Service Accounts,DC=aku,DC=com"
    ldap_bind_user_pass: ""
    ldap_user_nick_entry: "sAMAccountName"
    ldap_tls: false
    logic_settings:
      # max allowed threads for api logic
      api_max_thread: 50000
      sender_max_threads: 25
      timer_default: 5 # 30
    # enigma private_key_id
    enigma_pk_id: ""

    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - capi
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - capi
  #            topologyKey: failure-domain.beta.kubernetes.io/zone


  ########  Settings for services  ########

  # http-worker
  http:
    tag: "3.6.0.1"
    minReplicas: 3
    maxReplicas: 6
    resources:
      limits:
        cpu: 2
        memory: 2048Mi
      requests:
        cpu: 2
        memory: 2048Mi
    max_http_resp_size: "5242880"
    blocked_domains:
      - "169.254.169.254"
      - "mail.ru"
    tune:
      http_consumer_queues_count: 8
      ## The specified number of tcp connections will be created for each queue
      http_consumer_connections_per_queue: 1
      ## Virtual connections for one connections_per_queue
      http_consumer_channels_per_connection: 1
      ## The number of queues within the channel
      http_consumer_messages_prefetch_size_per_channel: 20
      consumer_settings_messages_prefetch_size_per_channel: 50
      ## The number of queues within the channel
      consumer_response_prefetch_size_per_channel: 50

    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - http-worker
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - http-worker
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # usercode
  usercode:
    tag: "7.2.1"
    minReplicas: 2
    maxReplicas: 4
    # application resources limits and requests
    resources:
      limits:
        cpu: 4
        memory: 2048Mi
      requests:
        cpu: 4
        memory: 2048Mi
    # enigma private_key_id
    enigma_pk_id: ""

    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - usercode
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - usercode
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # conveyor-worker
  worker:
    tag: "4.7.0.1"
    minReplicas: 3
    maxReplicas: 6
    # application resources limits and requests
    resources:
      limits:
        cpu: 2
        memory: 2000M
      requests:
        cpu: 2
        memory: 2000M
    # enigma private_key_id
    enigma_pk_id: ""
    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - worker
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - worker
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # mult
  mult:
    tag: "2.6.0.1"
    minReplicas: 1
    maxReplicas: 4
    ## pvc name if it already exist or was created manualy
    persistantVolumeClaimName: "mult-pvc"
    ## true if pvc for mult should be created automaticaly
    ## false if you already have pvc
    persistantVolumeClaimCreate: true
    # application resources limits and requests
    resources:
      limits:
        cpu: 2
        memory: 2048Mi
      requests:
        cpu: 2
        memory: 2048Mi
    # enigma private_key_id
    enigma_pk_id: ""

    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - mult
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - mult
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # webadm
  webadm:
    tag: "5.7.0"
    minReplicas: 1
    resources:
      limits:
        cpu: 200m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 512Mi
    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - corezoid-web-adm
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - corezoid-web-adm
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # web-superadm
  web_superadm:
    tag: "1.5.1"
    subdomain: "superadm"
    minReplicas: 1

  # syncapi
  syncapi:
    subdomain: "syncapi"
    tag: "2.1.0"
    minReplicas: 2
    maxReplicas: 6
    resources:
      limits:
        cpu: 2
        memory: 2048Mi
      requests:
        cpu: 2
        memory: 2048Mi

    affinity: {}
  #    # hard AZ-based affinity
  #      podAntiAffinity:
  #        requiredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #              - key: tier
  #                operator: In
  #                values:
  #                  - syncapi
  #            topologyKey: failure-domain.beta.kubernetes.io/zone
  #    # soft AZ-based affinity
  #      podAntiAffinity:
  #        preferredDuringSchedulingIgnoredDuringExecution:
  #          - labelSelector:
  #              matchExpressions:
  #                - key: tier
  #                  operator: In
  #                  values:
  #                    - syncapi
  #            topologyKey: failure-domain.beta.kubernetes.io/zone

  # merchant
  merchant:
    tag: "v0.0.27.2"
    enabled: true
    subdomain: "merchant"
    secret:
      ## true - secret will be created automaticaly with provided values
      ## false - secret should be created manualy
      create: true
      name: "merchant-secret"
      data:
        # login/secret for corezoid-merchant communications
        merchant_login: apiLogin1
        merchant_secret: I9EmB170XUbe
    # application resources limits and requests
    resources:
      limits:
        cpu: 500m
        memory: 800Mi
      requests:
        cpu: 100m
        memory: 500Mi

  # enigma global settings
  enigma:
    enabled: false
    encryption: false
    key_manager:
      tag: "1.1.0"
      aws_kms_role: ""
      minReplicas: 1
      maxReplicas: 1
      resources:
        limits:
          cpu: 1000m
          memory: 1300Mi
        requests:
          cpu: 350m
          memory: 500Mi

  # single-account
  sa:
    # true or false
    enabled: false
    google_client_id: ""
    google_client_secret: ""
  sa_web:
    subdomain: ""

  # gitcall | worker and rabbit settings
  gitcall:
    # true or false
    enabled: false
    mq_vhost: "/conveyor"
    dunder_mq_vhost: "/dundergitcall"


  # conf-agent-server
  conf_agent_server:
    tag: "1.5.1"
    minReplicas: 2
    maxReplicas: 4
    resources:
      limits:
        cpu: 1000m
        memory: 1000Mi
      requests:
        cpu: 1000m
        memory: 1000Mi

  limits:
    tag: "1.2.2"
    minReplicas: 2

  # global log level definition, info - default
  # available value info | warning | error | debug
  log_level: info
  # allows store crushdumps and send to Telegram chat
  store_dumps:
    enabled: false
    dumps_dir: /var/dumps/
    http_endpoint: http://dump-service:3000/upload
    pvc_size: 10Gi
    notification_url: http://dump-service:3000/telegram
    # domain name for dumps web ui
    subdomain: ""
    #    dump-k8s-public
    # how to create login and password
    # https://www.web2generators.com/apache-tools/htpasswd-generator
    base_auth:
      - admin:$apr1$kdvn7ybj$Wp1TO4qCvlTpUu1x248Nb0
    # How to create telegram bot and get chat ID
    # https://core.telegram.org/bots
    # To get chat id replace {BOT_TOKEN} and open link in a browser
    # https://api.telegram.org/bot{BOT_TOKEN}/getUpdates
    # telegram token
    telegram_token: ""
    # telegram chat id
    telegram_group: ""
    rotate:
      # dumps rotate interval (hourly|daily|weekly|monthly|yearly)
      interval: daily
      # number of rotation
      copies: 7
